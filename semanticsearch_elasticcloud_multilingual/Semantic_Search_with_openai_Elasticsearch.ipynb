{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGQL1nWnwjTD"
      },
      "source": [
        "## Elasticsearch with Multilingual-e5-small model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTCuvnkeuZA3"
      },
      "source": [
        "# Pre-Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SjiKkO0u75i"
      },
      "source": [
        "## Install necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u1JJs0_qt61C",
        "outputId": "81622c13-db96-4daa-828c-8e89d3808593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting eland\n",
            "  Downloading eland-8.14.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting elasticsearch\n",
            "  Downloading elasticsearch-8.14.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting pandas<2,>=1.5 (from eland)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from eland) (3.7.1)\n",
            "Requirement already satisfied: numpy<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from eland) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from eland) (24.1)\n",
            "Collecting elastic-transport<9,>=8.13 (from elasticsearch)\n",
            "  Downloading elastic_transport-8.13.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.7.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->eland) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->eland) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->eland) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->eland) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->eland) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->eland) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->eland) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2,>=1.5->eland) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->eland) (1.16.0)\n",
            "Downloading eland-8.14.0-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading elasticsearch-8.14.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.2/480.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading elastic_transport-8.13.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: elastic-transport, pandas, elasticsearch, eland\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed eland-8.14.0 elastic-transport-8.13.1 elasticsearch-8.14.0 pandas-1.5.3\n",
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.10/dist-packages (8.14.0)\n",
            "Requirement already satisfied: elastic-transport<9,>=8.13 in /usr/local/lib/python3.10/dist-packages (from elasticsearch) (8.13.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.7.4)\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install eland elasticsearch\n",
        "!pip install elasticsearch\n",
        "!pip install openai==0.28\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muCHNOETyW7U"
      },
      "source": [
        "## Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WRozLPut63i"
      },
      "outputs": [],
      "source": [
        "from elasticsearch import (Elasticsearch,helpers)\n",
        "from urllib.request import urlopen\n",
        "import getpass\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph_KxFCyyfWd"
      },
      "source": [
        "## Connect to Elasticsearch Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Elastic cloud connection\n",
        "CLOUD_ID = getpass.getpass(\"Enter Elastic Cloud ID:  \")   \n",
        "\n",
        "# Password for the 'elastic' user generated by Elasticsearch\n",
        "ELASTIC_PASSWORD = getpass.getpass(\"Enter Elastic password:  \")  \n",
        "\n",
        "# Create the client instance\n",
        "es = Elasticsearch(cloud_id=CLOUD_ID, basic_auth=(\"elastic\", ELASTIC_PASSWORD), request_timeout=3600)\n",
        "\n",
        "# Check the connection\n",
        "try:\n",
        "    # Ping the Elasticsearch cluster\n",
        "    if es.ping():\n",
        "        print(\"You have Successfully Connected with Elastic Cloud\")\n",
        "    else:\n",
        "        print(\"Failed to connect to Elastic Cloud\")\n",
        "except Exception as e:\n",
        "    print(f\"Error connecting to Elastic Cloud: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9BFcsP0y1ll"
      },
      "source": [
        "## Create pipeline ingesting Machine Leanrning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvMtTnm9t68p",
        "outputId": "21f4b7ef-d95c-45ca-dc70-3cdcd1499971"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ObjectApiResponse({'acknowledged': True})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating an ingest pipeline with inference processors to use multilingual-e5-small to infer against data that will be ingested in the pipeline.\n",
        "\n",
        "\n",
        "es.ingest.put_pipeline(\n",
        "    id=\"ecommerce-pipeline_1\",\n",
        "    processors=[\n",
        "        {\n",
        "            \"inference\": {\n",
        "                \"model_id\": \".multilingual-e5-small\",\n",
        "                \"target_field\": \"ml\",\n",
        "                \"field_map\": {\"description\": \"text_field\"},\n",
        "                \"inference_config\": {\n",
        "                    \"text_embedding\": {  # text_embedding inference type\n",
        "                        \"results_field\": \"embeddings\"\n",
        "                    }\n",
        "                },\n",
        "            }\n",
        "        },\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbAgKlRizQZ3"
      },
      "source": [
        "## Create Old Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr7epZqZt6_F",
        "outputId": "efd697a4-f554-4af7-e132-7196894b9325"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'ecommerce_old_index'})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Index to load products-ecommerce.json docs\n",
        "\n",
        "es.indices.create(\n",
        "    index=\"ecommerce_old_index\",\n",
        "    mappings={\n",
        "        \"properties\": {\n",
        "            \"product\": {\n",
        "                \"type\": \"text\",\n",
        "                \"fields\": {\"keyword\": {\"type\": \"keyword\",\"ignore_above\": 256}},\n",
        "            },\n",
        "            \"description\": {\n",
        "                \"type\": \"text\",\n",
        "                \"fields\": {\"keyword\": {\"type\": \"keyword\",\"ignore_above\": 256}},\n",
        "            },\n",
        "            \"category\": {\n",
        "                \"type\": \"text\",\n",
        "                \"fields\": {\"keyword\": {\"type\": \"keyword\",\"ignore_above\": 256}},\n",
        "            },\n",
        "        }\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZIajn65zVCZ"
      },
      "source": [
        "## Create New Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaElfsQUt7Be",
        "outputId": "8b72fc45-e494-4b22-f7ff-dd9dc448f3a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'ecommerce_new_index'})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "\n",
        "\n",
        "\n",
        "# Reindex index\n",
        "INDEX = \"ecommerce_new_index\"\n",
        "es.indices.create(\n",
        "    index=INDEX,\n",
        "    settings={\"index\": {\"number_of_shards\": 1, \"number_of_replicas\": 1}},\n",
        "    mappings={\n",
        "        \"properties\": {\n",
        "            \"product\": {\n",
        "                \"type\": \"text\",\n",
        "                \"fields\": {\"keyword\": {\"type\": \"keyword\",\"ignore_above\": 256}},\n",
        "            },\n",
        "            \"description\": {\n",
        "                \"type\": \"text\",\n",
        "                \"fields\": {\"keyword\": {\"type\": \"keyword\",\"ignore_above\": 256}},\n",
        "            },\n",
        "            \"category\": {\n",
        "                \"type\": \"text\",\n",
        "                \"fields\": {\"keyword\": {\"type\": \"keyword\",\"ignore_above\": 256}},\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuIEcfMozZqE"
      },
      "source": [
        "## Insert Data into Old Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gEwRQ88t7Dv",
        "outputId": "d955b519-cc79-43a6-feca-c2dfe92bfc69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done indexing documents into `ecommerce_old_index` index\n"
          ]
        }
      ],
      "source": [
        "#  dataset\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/02c01b3450e8ddc72ccec85d559eee5280c185ac/supporting-blog-content/lexical-and-semantic-search-with-elasticsearch/products-ecommerce.json\"  # json raw file - update the link here\n",
        "\n",
        "response = urlopen(url)\n",
        "\n",
        "# Load the response data into a JSON object\n",
        "data_json = json.loads(response.read())\n",
        "\n",
        "\n",
        "def create_index_body(doc):\n",
        "    \"\"\"Generate the body for an Elasticsearch document.\"\"\"\n",
        "    return {\n",
        "        \"_index\": \"ecommerce_old_index\",\n",
        "        \"_source\": doc,\n",
        "    }\n",
        "\n",
        "\n",
        "# Prepare the documents to be indexed\n",
        "documents = [create_index_body(doc) for doc in data_json]\n",
        "\n",
        "# Use helpers.bulk to index\n",
        "helpers.bulk(es, documents)\n",
        "\n",
        "print(\"Done indexing documents into `ecommerce_old_index` index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_MJM9P7zj--"
      },
      "source": [
        "## Insert data from Old Index to New Index through Pipeline of ML model taking one targeted column embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y54CDyVt7F-",
        "outputId": "3b69f1f6-96a2-441b-dd8c-c1844f080ee0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ObjectApiResponse({'took': 71333, 'timed_out': False, 'total': 2506, 'updated': 0, 'created': 2506, 'deleted': 0, 'batches': 3, 'version_conflicts': 0, 'noops': 0, 'retries': {'bulk': 0, 'search': 0}, 'throttled_millis': 0, 'requests_per_second': -1.0, 'throttled_until_millis': 0, 'failures': []})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reindex data from one index 'source' to another 'dest' with the 'ecommerce-pipeline' pipeline.\n",
        "\n",
        "es.reindex(\n",
        "    wait_for_completion=True,\n",
        "    source={\"index\": \"ecommerce_old_index\"},\n",
        "    dest={\"index\": \"ecommerce_new_index\", \"pipeline\": \"ecommerce-pipeline_1\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "512kvAkZ0J5m"
      },
      "source": [
        "## Semantic Search Using KNN without Chatgpt response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cU1QF61t7La",
        "outputId": "0bb7771b-0d48-4f83-fc2a-95baae775e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.930022\n",
            "Product: JBL Endurance DIVE Waterproof MP3 Player\n",
            "Category: Sports Equipment\n",
            "Description: is a waterproof MP3 player with built-in earbuds, perfect for listening to music while swimming or water sports.\n",
            "\n",
            "\n",
            "Score: 0.9296545\n",
            "Product: Bose SoundLink Revolve+ Portable Bluetooth Speaker\n",
            "Category: Bluetooth Speakers\n",
            "Description: is a portable and water-resistant Bluetooth speaker with 360-degree sound. It's great for indoor and outdoor listening.\n",
            "\n",
            "\n",
            "Score: 0.9239327\n",
            "Product: JBL Flip 5 Portable Bluetooth Speaker\n",
            "Category: Bluetooth Speakers\n",
            "Description: is a portable and waterproof Bluetooth speaker with powerful sound. It's perfect for outdoor gatherings and music on the go.\n",
            "\n",
            "\n",
            "Score: 0.92382467\n",
            "Product: UE Boom 3 Portable Bluetooth Speaker\n",
            "Category: Bluetooth Speakers\n",
            "Description: is a rugged and waterproof Bluetooth speaker with 360-degree sound. It's great for outdoor adventures and pool parties.\n",
            "\n",
            "\n",
            "Score: 0.923139\n",
            "Product: Yamaha P-515 Portable Digital Piano\n",
            "Category: Musical Instruments\n",
            "Description: is a portable digital piano with Natural Wood X keyboard and advanced piano sound. It is perfect for gigging musicians.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_keyword = \"provide me device for listening music\"\n",
        "\n",
        "\n",
        "response = es.search(\n",
        "    index=\"ecommerce_new_index\",\n",
        "    size=5,\n",
        "    knn={\n",
        "        \"field\": \"ml.embeddings\",\n",
        "        \"k\": 10,  # Number of nearest neighbors to return as top hits.\n",
        "        \"num_candidates\": 500,  # Number of nearest neighbor candidates to consider per shard. Increasing num_candidates tends to improve the accuracy of the final k results.\n",
        "        \"query_vector_builder\": {  # Object indicating how to build a query_vector. kNN search enables you to perform semantic search by using a previously deployed text embedding model.\n",
        "            \"text_embedding\": {\n",
        "                \"model_id\": \".multilingual-e5-small\",  # Text embedding model id \"multilingual-e5-small\"\n",
        "                \"model_text\": input_keyword,  # Query\n",
        "            }\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "for hit in response[\"hits\"][\"hits\"]:\n",
        "\n",
        "    score = hit[\"_score\"]\n",
        "    product = hit[\"_source\"][\"product\"]\n",
        "    category = hit[\"_source\"][\"category\"]\n",
        "    description = hit[\"_source\"][\"description\"]\n",
        "    print(\n",
        "        f\"\\nScore: {score}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\"\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iadyw_le0fBj"
      },
      "source": [
        "## Semantic Search Using KNN with Chatgpt response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjThErVQt7Td",
        "outputId": "e447af29-116b-4134-9840-d03d1a4818b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response: Certainly! Here are some men's fashion clothing options for a modern and fashionable look:\n",
            "\n",
            "1. Slim Fit Striped Shirt: A must-have shirt that offers a slim fit and stylish stripes for a modern appearance.\n",
            "  \n",
            "2. Tailored Dress Pants: A pair of well-fitted dress pants that exude sophistication and can be easily dressed up or down.\n",
            "\n",
            "3. Classic Leather Jacket: Elevate your outfit with a timeless leather jacket that adds a rugged yet refined touch to your style.\n",
            "\n",
            "4. Chelsea Boots: Complete your look with a pair of sleek Chelsea boots that are versatile enough for both casual and formal occasions.\n",
            "\n",
            "5. Statement Watch: Add a touch of elegance with a statement watch that not only tells time but also serves as a fashion accessory.\n",
            "\n",
            "These clothing items will help you achieve a fashionable and polished look for various occasions.\n",
            "Source Information: \n",
            "Score: 0.9108627\n",
            "Product: Closet Rod Dividers\n",
            "Category: Storage & Organization\n",
            "Description: are dividers that fit on closet rods, helping to separate and organize clothing.\n",
            "\n",
            "Score: 0.9101517\n",
            "Product: Slim Fit Striped Shirt\n",
            "Category: Men's Clothing\n",
            "Description: is a shirt with slim fit and stripes, offering a modern and fashionable look.\n",
            "\n",
            "Score: 0.9100834\n",
            "Product: Closet Hanging Storage Shelves\n",
            "Category: Storage & Organization\n",
            "Description: are shelves that hang in the closet, providing additional storage for clothes.\n",
            "\n",
            "Score: 0.9097253\n",
            "Product: Boho Fringe Vest\n",
            "Category: Women's Clothing\n",
            "Description: is a vest with bohemian-inspired fringe details, perfect for adding texture to outfits.\n",
            "\n",
            "Score: 0.9083122\n",
            "Product: Boho Embroidered Jacket\n",
            "Category: Women's Clothing\n",
            "Description: is a jacket with bohemian-inspired embroidery, perfect for adding flair to outfits.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from elasticsearch import Elasticsearch\n",
        "import openai\n",
        "\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = 'OPENAI_API_KEY'\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Initialize the Elasticsearch client\n",
        "es = Elasticsearch(cloud_id=\"My_deployment:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyQwYWQ2NTBlMzJiMTE0OGU4YWUyNTUwNmI0NmE3Yjc2MiRkZGIyYTdhZTc3YjY0NzRmOTdhZjAwNjJhNWI1NGM1Ng==\", basic_auth=(\"elastic\", \"mx8WQ6gXqkAayGL6EfMNrmj5\"), request_timeout=3600)\n",
        "\n",
        "# KNN search parameters\n",
        "input_keyword = \"provide me mens fashion clothes\"\n",
        "\n",
        "# Perform the KNN search\n",
        "response = es.search(\n",
        "    index=\"ecommerce_new_index\",\n",
        "    size=5,\n",
        "    knn={\n",
        "        \"field\": \"ml.embeddings\",\n",
        "        \"k\": 10,\n",
        "        \"num_candidates\": 500,\n",
        "        \"query_vector_builder\": {\n",
        "            \"text_embedding\": {\n",
        "                \"model_id\": \".multilingual-e5-small\",\n",
        "                \"model_text\": input_keyword,\n",
        "            }\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "# Process the search results\n",
        "search_result = ''\n",
        "for hit in response[\"hits\"][\"hits\"]:\n",
        "    score = hit[\"_score\"]\n",
        "    product = hit[\"_source\"][\"product\"]\n",
        "    category = hit[\"_source\"][\"category\"]\n",
        "    description = hit[\"_source\"][\"description\"]\n",
        "    search_result += f\"Score: {score}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\\n\"\n",
        "\n",
        "# Generate a response using ChatGPT-3.5\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Answer this user query: \" + input_keyword + \" with the following context: \" + search_result}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Retrieve and print the response\n",
        "chatgpt_response = completion.choices[0].message['content']\n",
        "print(f\"Response: {chatgpt_response}\")\n",
        "print(f\"Source Information: \\n{search_result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LDXlv1i5C2M"
      },
      "source": [
        "# Post Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x9t8tYWuxrz"
      },
      "source": [
        "## Install necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "slrdK2Ap5Bzf",
        "outputId": "b5b479c5-9581-4ee6-fe0b-032381d1c200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.39.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.1.1 (from gradio)\n",
            "  Downloading gradio_client-1.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.1.1->gradio) (2024.6.1)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.1.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.39.0-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.1.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.2/318.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.5.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvloop, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, ffmpy, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.0\n",
            "    Uninstalling tomlkit-0.13.0:\n",
            "      Successfully uninstalled tomlkit-0.13.0\n",
            "Successfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 ffmpy-0.4.0 gradio-4.39.0 gradio-client-1.1.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.6 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.5.5 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 uvicorn-0.30.3 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install eland elasticsearch\n",
        "!pip install elasticsearch\n",
        "!pip install openai==0.28\n",
        "!pip install streamlit\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUS83gvEvJt4"
      },
      "source": [
        "## Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FJaZOXY5B5H"
      },
      "outputs": [],
      "source": [
        "from elasticsearch import (Elasticsearch,helpers)\n",
        "import getpass\n",
        "import openai\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V7oooDDvj3Q"
      },
      "source": [
        "## Connect to Elasticsearch Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0PGApJf5CHm",
        "outputId": "db11368c-5e34-4cb7-a78c-f55b39fa14df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Elastic Cloud ID:  ··········\n",
            "Enter Elastic password:  ··········\n",
            "You have Successfully Connected with Elastic Cloud\n"
          ]
        }
      ],
      "source": [
        "# Elastic cloud connection\n",
        "CLOUD_ID = getpass.getpass(\"Enter Elastic Cloud ID:  \")   \n",
        "\n",
        "# Password for the 'elastic' user generated by Elasticsearch\n",
        "ELASTIC_PASSWORD = getpass.getpass(\"Enter Elastic password:  \")  \n",
        "\n",
        "# Create the client instance\n",
        "es = Elasticsearch(cloud_id=CLOUD_ID, basic_auth=(\"elastic\", ELASTIC_PASSWORD), request_timeout=3600)\n",
        "\n",
        "# Check the connection\n",
        "try:\n",
        "    # Ping the Elasticsearch cluster\n",
        "    if es.ping():\n",
        "        print(\"You have Successfully Connected with Elastic Cloud\")\n",
        "    else:\n",
        "        print(\"Failed to connect to Elastic Cloud\")\n",
        "except Exception as e:\n",
        "    print(f\"Error connecting to Elastic Cloud: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbVJcrmdvq6_"
      },
      "source": [
        "## Semantic Search using KNN without chatgpt response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zIilymE5CJR",
        "outputId": "82865325-dba9-4caf-913c-d41b595dc2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.930022\n",
            "Product: JBL Endurance DIVE Waterproof MP3 Player\n",
            "Category: Sports Equipment\n",
            "Description: is a waterproof MP3 player with built-in earbuds, perfect for listening to music while swimming or water sports.\n",
            "\n",
            "\n",
            "Score: 0.9296545\n",
            "Product: Bose SoundLink Revolve+ Portable Bluetooth Speaker\n",
            "Category: Bluetooth Speakers\n",
            "Description: is a portable and water-resistant Bluetooth speaker with 360-degree sound. It's great for indoor and outdoor listening.\n",
            "\n",
            "\n",
            "Score: 0.9239327\n",
            "Product: JBL Flip 5 Portable Bluetooth Speaker\n",
            "Category: Bluetooth Speakers\n",
            "Description: is a portable and waterproof Bluetooth speaker with powerful sound. It's perfect for outdoor gatherings and music on the go.\n",
            "\n",
            "\n",
            "Score: 0.92382467\n",
            "Product: UE Boom 3 Portable Bluetooth Speaker\n",
            "Category: Bluetooth Speakers\n",
            "Description: is a rugged and waterproof Bluetooth speaker with 360-degree sound. It's great for outdoor adventures and pool parties.\n",
            "\n",
            "\n",
            "Score: 0.923139\n",
            "Product: Yamaha P-515 Portable Digital Piano\n",
            "Category: Musical Instruments\n",
            "Description: is a portable digital piano with Natural Wood X keyboard and advanced piano sound. It is perfect for gigging musicians.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "\n",
        "\n",
        "es = Elasticsearch(cloud_id=\"My_deployment:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyQyYTFmZTY2Yjk5MTQ0YmJjOWE3NjQ1NmNhYWM4ZmEyMSQ5NTY0Zjk5OTI0ODk0YTk1YjI0NDUyYTJiZTJhNmEzNg==\", basic_auth=(\"elastic\", \"Y0H9aCTnbBrR6LPoQdnx17a5\"), request_timeout=3600)\n",
        "\n",
        "\n",
        "\n",
        "input_keyword = \"provide me device for listening music\"\n",
        "\n",
        "response = es.search(\n",
        "    index=\"ecommerce_new_index\",\n",
        "    size=5,\n",
        "    knn={\n",
        "        \"field\": \"ml.embeddings\",\n",
        "        \"k\": 10,  # Number of nearest neighbors to return as top hits.\n",
        "        \"num_candidates\": 500,  # Number of nearest neighbor candidates to consider per shard. Increasing num_candidates tends to improve the accuracy of the final k results.\n",
        "        \"query_vector_builder\": {  # Object indicating how to build a query_vector. kNN search enables you to perform semantic search by using a previously deployed text embedding model.\n",
        "            \"text_embedding\": {\n",
        "                \"model_id\": \".multilingual-e5-small\",  # Text embedding model id \".multilingual-e5-small\"\n",
        "                \"model_text\": input_keyword,  # Query\n",
        "            }\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "for hit in response[\"hits\"][\"hits\"]:\n",
        "\n",
        "    score = hit[\"_score\"]\n",
        "    product = hit[\"_source\"][\"product\"]\n",
        "    category = hit[\"_source\"][\"category\"]\n",
        "    description = hit[\"_source\"][\"description\"]\n",
        "    print(\n",
        "        f\"\\nScore: {score}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\"\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap0LaQQUwQke"
      },
      "source": [
        "## Semantic Search using KNN with chatgpt response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5CKlMSb6XQN",
        "outputId": "22552c84-9064-4862-aec0-0851442e3136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response: Based on the context provided, here are some earphone options for you:\n",
            "\n",
            "1. Jaybird Vista True Wireless Sport Earbuds\n",
            "- Category: Sports Equipment\n",
            "- Description: These wireless earbuds are specifically designed for sports and workouts, offering excellent sound quality and a secure fit.\n",
            "\n",
            "2. Beats Powerbeats Pro Wireless Earphones\n",
            "- Category: Wireless Earbuds\n",
            "- Description: These true wireless earphones are sweat and water resistant, providing powerful sound and a secure fit ideal for sports and workouts.\n",
            "\n",
            "3. Beats Studio Buds Wireless Earphones\n",
            "- Category: Wireless Earbuds\n",
            "- Description: These true wireless earphones feature active noise cancellation, sweat and water resistance, immersive sound, and a comfortable fit.\n",
            "\n",
            "These earphone options cater to different needs and preferences, so you can choose based on your specific requirements for sports, workouts, or everyday use.\n",
            "Source Information: \n",
            "Score: 0.9170399\n",
            "Product: Jaybird Vista True Wireless Sport Earbuds\n",
            "Category: Sports Equipment\n",
            "Description: are wireless earbuds designed for sports and workouts, providing excellent sound quality and a secure fit.\n",
            "\n",
            "Score: 0.9167894\n",
            "Product: Beats Powerbeats Pro Wireless Earphones\n",
            "Category: Wireless Earbuds\n",
            "Description: are true wireless earphones with sweat and water resistance. They offer powerful sound and a secure fit for sports and workouts.\n",
            "\n",
            "Score: 0.91613734\n",
            "Product: Bose Noise Cancelling Headphones 700\n",
            "Category: Headphones\n",
            "Description: are premium over-ear headphones with adaptive noise-canceling technology. They provide exceptional sound quality and a comfortable fit for all-day use.\n",
            "\n",
            "Score: 0.9153155\n",
            "Product: Beats Studio Buds Wireless Earphones\n",
            "Category: Wireless Earbuds\n",
            "Description: are true wireless earphones with active noise cancellation and sweat and water resistance. They offer immersive sound and a comfortable fit.\n",
            "\n",
            "Score: 0.9148288\n",
            "Product: Sony WH-1000XM4 Wireless Noise-Canceling Headphones\n",
            "Category: Headphones\n",
            "Description: are premium over-ear headphones with industry-leading noise-canceling technology. They deliver high-fidelity audio, long battery life, and a comfortable design for extended listening sessions.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# response with chatgpt\n",
        "from elasticsearch import Elasticsearch\n",
        "import os\n",
        "import openais\n",
        "\n",
        "# Set the API key for OpenAI\n",
        "os.environ['OPENAI_API_KEY'] = \"OPENAI_API_KEY\"\n",
        "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize the Elasticsearch client\n",
        "es = Elasticsearch(cloud_id=\"My_deployment:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyQwYWQ2NTBlMzJiMTE0OGU4YWUyNTUwNmI0NmE3Yjc2MiRkZGIyYTdhZTc3YjY0NzRmOTdhZjAwNjJhNWI1NGM1Ng==\", basic_auth=(\"elastic\", \"Y0H9aCTnbBrR6LPoQdnx17a5\"), request_timeout=3600)\n",
        "\n",
        "# KNN search parameters\n",
        "input_keyword = \"provide me earphones\"\n",
        "\n",
        "# Perform the KNN search\n",
        "response = es.search(\n",
        "    index=\"ecommerce_new_index\",\n",
        "    size=5,\n",
        "    knn={\n",
        "        \"field\": \"ml.embeddings\",\n",
        "        \"k\": 10,\n",
        "        \"num_candidates\": 500,\n",
        "        \"query_vector_builder\": {\n",
        "            \"text_embedding\": {\n",
        "                \"model_id\": \".multilingual-e5-small\",\n",
        "                \"model_text\": input_keyword,\n",
        "            }\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "# Process the search results\n",
        "search_result = ''\n",
        "for hit in response[\"hits\"][\"hits\"]:\n",
        "    score = hit[\"_score\"]\n",
        "    product = hit[\"_source\"][\"product\"]\n",
        "    category = hit[\"_source\"][\"category\"]\n",
        "    description = hit[\"_source\"][\"description\"]\n",
        "    search_result += f\"Score: {score}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\\n\"\n",
        "\n",
        "# Generate a response using ChatGPT-3.5\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Answer this user query: \" + input_keyword + \" with the following context: \" + search_result}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Retrieve and print the response\n",
        "chatgpt_response = completion.choices[0].message['content']\n",
        "print(f\"Response: {chatgpt_response}\")\n",
        "print(f\"Source Information: \\n{search_result}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-f8c3ELwLP_"
      },
      "source": [
        "# Streamlit App Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqDsv3ze1Kaz"
      },
      "source": [
        "###  \n",
        "1. Create one file \"app.py\" and copy this code and paste in \"app.py\" file then save it\n",
        "\n",
        "2. Run \"!pip install streamlit -q\" code for installing streamlit in colab\n",
        "\n",
        "3. Run \"!wget -q -O - ipv4.icanhazip.com\" for getting tunnel port\n",
        "\n",
        "4. Run \"!streamlit run app.py & npx localtunnel --port 8501\" we get our link click on link then past tunnel port for redirecting our application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StRPPGPZt7bh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import streamlit as st\n",
        "from elasticsearch import Elasticsearch\n",
        "import openai\n",
        "\n",
        "# Set the API key for OpenAI\n",
        "os.environ['OPENAI_API_KEY'] = \"OPENAI_API_KEY\"\n",
        "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize the Elasticsearch client\n",
        "try:\n",
        "    es = Elasticsearch(cloud_id=\"My_deployment:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyQwYWQ2NTBlMzJiMTE0OGU4YWUyNTUwNmI0NmE3Yjc2MiRkZGIyYTdhZTc3YjY0NzRmOTdhZjAwNjJhNWI1NGM1Ng==\", basic_auth=(\"elastic\", \"Y0H9aCTnbBrR6LPoQdnx17a5\"), request_timeout=3600)\n",
        "except ConnectionError as e:\n",
        "    st.error(f\"Connection Error: {e}\")\n",
        "\n",
        "if es.ping():\n",
        "    st.success(\"Successfully connected to Elasticsearch!\")\n",
        "else:\n",
        "    st.error(\"Oops! Cannot connect to Elasticsearch.\")\n",
        "\n",
        "# KNN search function\n",
        "def search(input_keyword):\n",
        "    response = es.search(\n",
        "        index=\"ecommerce_new_index\",\n",
        "        size=5,\n",
        "        knn={\n",
        "            \"field\": \"ml.embeddings\",\n",
        "            \"k\": 10,\n",
        "            \"num_candidates\": 500,\n",
        "            \"query_vector_builder\": {\n",
        "                \"text_embedding\": {\n",
        "                    \"model_id\": \".multilingual-e5-small\",\n",
        "                    \"model_text\": input_keyword,\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "    )\n",
        "    results = response[\"hits\"][\"hits\"]\n",
        "    return results\n",
        "\n",
        "# Function to generate ChatGPT-3.5 response\n",
        "def generate_chatgpt_response(input_keyword, search_results):\n",
        "    search_result_text = \"\"\n",
        "    for hit in search_results:\n",
        "        score = hit[\"_score\"]\n",
        "        product = hit[\"_source\"][\"product\"]\n",
        "        category = hit[\"_source\"][\"category\"]\n",
        "        description = hit[\"_source\"][\"description\"]\n",
        "        search_result_text += f\"Score: {score}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\\n\"\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Answer this user query: \" + input_keyword + \" with the following context: \" + search_result_text}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    chatgpt_response = completion.choices[0]['message']['content']\n",
        "    return chatgpt_response\n",
        "\n",
        "# UI using Streamlit\n",
        "def main():\n",
        "    st.title(\"Search Ecommerce Product\")\n",
        "\n",
        "    # Input: User enters search query\n",
        "    search_query = st.text_area(\"Enter your search query\")\n",
        "\n",
        "    # Button: User triggers the search\n",
        "    if st.button('Search'):\n",
        "        if search_query:\n",
        "            # Perform the search and get results\n",
        "            results = search(search_query)\n",
        "\n",
        "            # Display search results\n",
        "            st.subheader(\"Search Results\")\n",
        "            for result in results:\n",
        "                with st.container():\n",
        "                    if '_source' in result:\n",
        "                        try:\n",
        "                            st.header(f\"{result['_source']['product']}\")\n",
        "                        except Exception as e:\n",
        "                            st.error(f\"Error: {e}\")\n",
        "\n",
        "                        try:\n",
        "                            st.write(f\"Score: {result['_score']}\")\n",
        "                        except Exception as e:\n",
        "                            st.error(f\"Error: {e}\")\n",
        "\n",
        "                        st.divider()\n",
        "\n",
        "                        try:\n",
        "                            st.write(f\"Category: {result['_source']['category']}\")\n",
        "                        except Exception as e:\n",
        "                            st.error(f\"Error: {e}\")\n",
        "\n",
        "                        st.divider()\n",
        "\n",
        "                        try:\n",
        "                            st.write(f\"Description: {result['_source']['description']}\")\n",
        "                        except Exception as e:\n",
        "                            st.error(f\"Error: {e}\")\n",
        "\n",
        "                        st.divider()\n",
        "\n",
        "            # Generate and display ChatGPT-3.5 response\n",
        "            chatgpt_response = generate_chatgpt_response(search_query, results)\n",
        "            st.subheader(\"ChatGPT-3.5 Response\")\n",
        "            st.write(chatgpt_response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaFDePwZt7em"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku8OZlpUwUcb",
        "outputId": "24f058ce-b18d-4ef0-8b25-1e483ffbccdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "104.196.209.33\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTQDM3r1wUg8",
        "outputId": "ee662798-6e9e-4c9c-9606-4c8aa5e4a301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.196.209.33:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "  localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\u001b[K\u001b[?25hyour url is: https://silly-parents-know.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03vgRZObS_Hv"
      },
      "source": [
        "# Gradio App Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "4UCv2nYBcapv",
        "outputId": "a63f46b9-22dc-4279-ff25-8ce182dba433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully connected to Elasticsearch!\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://4a73be6160f99c3da7.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://4a73be6160f99c3da7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://4a73be6160f99c3da7.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from elasticsearch import Elasticsearch\n",
        "import openai\n",
        "import gradio as gr\n",
        "\n",
        "# Set the API key for OpenAI\n",
        "os.environ['OPENAI_API_KEY'] = \"OPENAI_API_KEY\"\n",
        "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize the Elasticsearch client\n",
        "try:\n",
        "    es = Elasticsearch(\n",
        "        cloud_id=\"My_deployment:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyQwYWQ2NTBlMzJiMTE0OGU4YWUyNTUwNmI0NmE3Yjc2MiRkZGIyYTdhZTc3YjY0NzRmOTdhZjAwNjJhNWI1NGM1Ng==\",\n",
        "        basic_auth=(\"elastic\", \"Y0H9aCTnbBrR6LPoQdnx17a5\"),\n",
        "        request_timeout=3600\n",
        "    )\n",
        "    if es.ping():\n",
        "        print(\"Successfully connected to Elasticsearch!\")\n",
        "    else:\n",
        "        print(\"Oops! Cannot connect to Elasticsearch.\")\n",
        "except Exception as e:\n",
        "    print(f\"Connection Error: {e}\")\n",
        "\n",
        "# KNN search function\n",
        "def search(input_keyword):\n",
        "    try:\n",
        "        response = es.search(\n",
        "            index=\"ecommerce_new_index\",\n",
        "            size=5,\n",
        "            knn={\n",
        "                \"field\": \"ml.embeddings\",\n",
        "                \"k\": 10,\n",
        "                \"num_candidates\": 500,\n",
        "                \"query_vector_builder\": {\n",
        "                    \"text_embedding\": {\n",
        "                        \"model_id\": \".multilingual-e5-small\",\n",
        "                        \"model_text\": input_keyword,\n",
        "                    }\n",
        "                },\n",
        "            },\n",
        "        )\n",
        "        results = response[\"hits\"][\"hits\"]\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error performing search: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to generate ChatGPT-3.5 response\n",
        "def generate_chatgpt_response(input_keyword, search_results):\n",
        "    search_result_text = \"\"\n",
        "    for hit in search_results:\n",
        "        score = hit[\"_score\"]\n",
        "        product = hit[\"_source\"][\"product\"]\n",
        "        category = hit[\"_source\"][\"category\"]\n",
        "        description = hit[\"_source\"][\"description\"]\n",
        "        search_result_text += f\"Score: {score}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\\n\"\n",
        "\n",
        "    try:\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": \"Answer this user query: \" + input_keyword + \" with the following context: \" + search_result_text}\n",
        "            ]\n",
        "        )\n",
        "        chatgpt_response = completion.choices[0]['message']['content']\n",
        "        return chatgpt_response\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating ChatGPT response: {e}\")\n",
        "        return \"Error generating response.\"\n",
        "\n",
        "# Function to handle the search and generate responses\n",
        "def handle_search(search_query):\n",
        "    results = search(search_query)\n",
        "\n",
        "    # Display search results\n",
        "    search_result_str = \"\"\n",
        "    for result in results:\n",
        "        if '_source' in result:\n",
        "            try:\n",
        "                search_result_str += f\"Product: {result['_source']['product']}\\n\"\n",
        "            except Exception as e:\n",
        "                search_result_str += f\"Error: {e}\\n\"\n",
        "\n",
        "            try:\n",
        "                search_result_str += f\"Score: {result['_score']}\\n\"\n",
        "            except Exception as e:\n",
        "                search_result_str += f\"Error: {e}\\n\"\n",
        "\n",
        "            search_result_str += \"-------------------------\\n\"\n",
        "\n",
        "            try:\n",
        "                search_result_str += f\"Category: {result['_source']['category']}\\n\"\n",
        "            except Exception as e:\n",
        "                search_result_str += f\"Error: {e}\\n\"\n",
        "\n",
        "            search_result_str += \"-------------------------\\n\"\n",
        "\n",
        "            try:\n",
        "                search_result_str += f\"Description: {result['_source']['description']}\\n\"\n",
        "            except Exception as e:\n",
        "                search_result_str += f\"Error: {e}\\n\"\n",
        "\n",
        "            search_result_str += \"=========================\\n\"\n",
        "\n",
        "    chatgpt_response = generate_chatgpt_response(search_query, results)\n",
        "\n",
        "    return search_result_str, chatgpt_response\n",
        "\n",
        "# Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=handle_search,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your search query\"),\n",
        "    outputs=[gr.Textbox(label=\"Search Results\"), gr.Textbox(label=\"ChatGPT-3.5 Response\")],\n",
        "    title=\"Search Ecommerce Product\",\n",
        "    description=\"Enter a search query to find products and get responses from ChatGPT-3.5 based on search results.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PTCuvnkeuZA3",
        "8SjiKkO0u75i",
        "muCHNOETyW7U",
        "ph_KxFCyyfWd",
        "s9BFcsP0y1ll",
        "bbAgKlRizQZ3",
        "DZIajn65zVCZ",
        "VuIEcfMozZqE",
        "s_MJM9P7zj--",
        "512kvAkZ0J5m",
        "iadyw_le0fBj",
        "3LDXlv1i5C2M",
        "-x9t8tYWuxrz",
        "iUS83gvEvJt4",
        "9V7oooDDvj3Q",
        "vbVJcrmdvq6_",
        "ap0LaQQUwQke",
        "e-f8c3ELwLP_",
        "hqDsv3ze1Kaz",
        "03vgRZObS_Hv"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
